### üìì Carnet de Bord : D√©veloppement U-Net Deblurring

#### 1. Probl√©matique Initiale & Contraintes
* **Architecture de base :** U-Net standard (2015).
* **Probl√®me :** Mod√®le de ~28M √† 30M de param√®tres trop lourd pour les ressources disponibles (Google Colab Free / MacBook MPS).
    * *Sympt√¥mes :* Timeout apr√®s quelques epochs, OOM (Out of Memory), it√©rations trop lentes.
* **Objectif :** Cr√©er une architecture "Lightweight" (< 5M params) capable d'apprendre efficacement sans sacrifier la capacit√© de reconstruction.

#### 2. Optimisation de l'Architecture (V1)
* **R√©duction des param√®tres :** Passage de 28M √† ~3M.
    * Remplacement des Convolutions Standards par des **Depthwise Separable Convolutions (DSConv)** (Gain : facteur ~8 sur les poids).
    * R√©duction du nombre de filtres initiaux (`start_filters`) de 64 √† 32.
    * Remplacement des `ConvTranspose2d` (lourdes, artefacts damier) par `Upsample Bilinear` + `Conv`.
* **Choix structurels :**
    * Maintien d'une convolution standard 4x4 (stride 2) pour le *Downsampling* afin de pr√©server l'information spatiale critique (responsable d'1M de params √† elle seule, mais jug√©e n√©cessaire).
    * **Global Residual Connection :** Adoption de la strat√©gie $Output = Input + Network(Input)$ pour forcer le r√©seau √† apprendre uniquement le r√©sidu (le flou) plut√¥t que de reconstruire l'image enti√®re.

#### 3. Strat√©gie de Donn√©es (Data Pipeline)
* **Training vs Inference :**
    * Entra√Ænement sur des **Random Crops (256x256)** pour g√©rer la VRAM et augmenter la diversit√© locale.
    * Validation/Test sur image compl√®te via strat√©gie de **Tiling (Tuilage)** avec *Overlap* et *Blending* pour √©viter les effets de bord sur les images HD (1280x720).
* **Data Augmentation (Crucial pour le d√©floutage) :**
    * Flip Horizontal & Vertical.
    * **Rotation 90¬∞/180¬∞/270¬∞ :** Indispensable pour varier la direction des vecteurs de flou de mouvement (transformer un flou gauche-droite en haut-bas).
    * *Note :* Application stricte de la "Joint Transform" (m√™me seed al√©atoire pour l'image floue et l'image nette).

#### 4. Adaptation Mat√©rielle (MacBook MPS)
* **Optimisation I/O :** Passage de `num_workers=4` √† `num_workers=0` pour √©viter les instabilit√©s du multiprocessing sur puce Apple Silicon.
* **Gestion M√©moire (VRAM 16Go) :**
    * D√©tection d'un OOM avec Batch Size 32 + Mod√®le 3M.
    * Ajustement du **Batch Size √† 16** (ou 32 avec *Gradient Accumulation* simul√©).
    * Utilisation de `torch.mps.empty_cache()` et `clip_grad_norm_` pour la stabilit√©.

#### 5. Analyse du Run #1 (Night Run)
* **R√©sultats :**
    * Training PSNR : **29.32 dB**
    * Validation PSNR : **27.50 dB**
* **Observations :**
    * Le mod√®le apprend bien (pas de divergence).
    * L'√©cart Train/Val (1.8 dB) sugg√®re un l√©ger "Generalization Gap", potentiellement d√ª au fait que les crops d'entra√Ænement sont parfois "faciles" (ciel uni) vs les crops de validation centr√©s (objets complexes).
    * **Probl√®me Majeur :** Le Learning Rate est rest√© constant (`2e-4`). Le scheduler `ReduceLROnPlateau` √©tait trop timide (patience trop √©lev√©e ou seuil non atteint), emp√™chant le mod√®le d'affiner les micro-d√©tails (convergence fine).

#### 6. Plan d'Action pour le Run #2 (V2)
Pour viser > 28.5 dB en validation :

1.  **Architecture (Scale Up) :** Augmentation de la largeur du mod√®le. Passage de `start_filters=32` √† **48** (environ 6.5M params) pour augmenter la capacit√© de m√©morisation des textures complexes.
2.  **Scheduler :** Remplacement de `ReduceLROnPlateau` par **`CosineAnnealingLR`**.
    * *But :* Forcer math√©matiquement la descente du LR jusqu'√† `1e-6` √† la fin de l'entra√Ænement pour garantir la phase de finition ("Fine-tuning").
3.  **R√©gularisation :**
    * Augmentation du **Weight Decay** de `1e-4` √† `1e-3` pour compenser l'augmentation de la taille du mod√®le et √©viter l'overfitting.
    * Ajout de **ColorJitter** (tr√®s l√©ger) dans l'augmentation de donn√©es pour robustifier le mod√®le face aux variations colorim√©triques.

#### 7. Intermediate Analysis (Run with Cosine Scheduler)
* **Results Achieved:**
    * **Validation PSNR:** Reached a stable plateau at **28.03 dB** (Target 28+ reached).
    * **Train PSNR:** Oscillating around **29.7 dB**.
    * **Scheduler Behavior:** The switch to `CosineAnnealingLR` is a total success. The learning curve shows a "smooth landing" and much better convergence compared to the previous plateau strategy.
* **Gap Diagnosis (Generalization Gap ~1.7 dB):**
    * The model learns well but seems to hit a ceiling in validation.
    * **Critical Discovery (Bug Fix):** Identified a logic error in `GoProDataset`. Random rotations (0, 90, 180, 270¬∞) were being applied **during validation as well** (missing indentation under `if self.is_train:`).
    * *Impact:* Validation was artificially noisy and harder than intended, likely underestimating the model's true performance.

#### 8. Optimisation Finale pour la V3 (Objectif 28.5+ dB)
Pour maximiser la performance et corriger le gap Train/Val, la strat√©gie suivante est adopt√©e :

* **A. Correction du Pipeline de Donn√©es :**
    * **Fix Rotation :** Restriction des rotations al√©atoires au mode `train` uniquement.
    * **Fix `ColorJitter` :** Correction du crash `TypeError` sur les param√®tres `hue` et impl√©mentation d'une synchronisation manuelle stricte pour garantir que l'image floue et nette subissent exactement la m√™me variation colorim√©trique.

* **B. Strat√©gie "Data Scale-Up" Rigoureuse (Split par S√©quence) :**
    * *Probl√®me Identifi√© :* Le dataset GoPro est constitu√© de s√©quences vid√©o. Un "Random Shuffle" simple des images cr√©erait une **fuite de donn√©es (Data Leakage)** massive : le mod√®le verrait la frame $t$ dans le Train et la frame $t+1$ (quasi-identique) dans la Validation, faussant le score. 
    * *Solution Scientifique :* Adoption d'un **Split par S√©quence Vid√©o**.
        * Les images sont group√©es par dossier parent (S√©quence).
        * Le m√©lange et la d√©coupe se font sur les *noms de s√©quences*, et non sur les images individuelles.
    * *Action :* R√©allocation dynamique de s√©quences du set de Test original vers le Train pour atteindre un ratio **~90% Train / 10% Val** (au lieu de 66/33).
    * *Gain Double :*
        1.  **Performance :** Le mod√®le s'entra√Æne sur ~2800 images (+33%), augmentant la diversit√© des sc√®nes apprises.
        2.  **Rigueur :** Garantie absolue qu'aucune image de validation ne provient d'une vid√©o vue √† l'entra√Ænement. La validation teste r√©ellement la g√©n√©ralisation sur une sc√®ne inconnue.

* **C. Raffinements de R√©gularisation :**
    * **Soft Color Jitter :** Ajout d'une variation al√©atoire l√©g√®re ($\pm 15\%$) de luminosit√©, contraste et saturation.
    * *But :* Forcer le mod√®le √† g√©n√©raliser sur les structures g√©om√©triques plut√¥t que de m√©moriser les histogrammes de couleurs sp√©cifiques des sc√®nes GoPro.

* **Configuration Finale Run V3 :**
    * **Architecture :** `LightweightUNet` (48 filtres initiaux).
    * **Batch Size :** 8 (avec *Gradient Accumulation* si instable).
    * **Scheduler :** `CosineAnnealingLR` (T_max=150).
    * **Dataset :** Split par S√©quence 90/10 + Augmentations corrig√©es.

    Voici la mise √† jour de ton Carnet de Bord avec les r√©sultats exceptionnels d'aujourd'hui et le plan pour la suite.



#### 9. Analyse du Run #3 (V3 - "La Perc√©e")
* **R√©sultats Exceptionnels :**
    * **Validation PSNR (Best) :** **31.15 dB** (Objectif initial 28.5 dB explos√© de +2.6 dB).
    * **Full Resolution PSNR (Reality Check) :** **29.57 dB** (Moyenne sur l'ensemble du dataset 1280x720).
    * *Distribution :* Courbe gaussienne saine, avec des pics de r√©ussite > 35 dB.
* **Ph√©nom√®ne Notable : Validation > Train**
    * La courbe de Validation est rest√©e constamment au-dessus de la courbe de Training.
    * *Interpr√©tation :* Le mod√®le s'entra√Æne en "Mode Difficile" (Jitter + Rotations + Random Crops souvent vides/difficiles) et est √©valu√© en "Mode Normal" (Center Crops + Couleurs r√©elles). Cela confirme une **absence totale d'overfitting** et une excellente robustesse.
* **Facteurs Cl√©s du Succ√®s :**
    1.  **Correction Bug Validation :** La suppression des rotations en validation a stabilis√© la mesure.
    2.  **Data Scale-Up :** L'ajout de 33% de donn√©es suppl√©mentaires (via le Split par S√©quence) a massivement boost√© la capacit√© de g√©n√©ralisation.
    3.  **Cosine Scheduler :** La courbe de PSNR montre une mont√©e continue jusqu'√† la derni√®re epoch (150), validant que la baisse progressive du Learning Rate a permis de "polir" le r√©sultat final.

#### 10. Prochaines √âtapes & Perspectives
Maintenant que le mod√®le "Champion" (avec Instance Norm) est s√©curis√©, l'exploration continue pour tenter d'atteindre la perfection visuelle.

* **A. Le Challenger "No-Norm" (Run V4) :**
    * *Hypoth√®se :* La normalisation (`InstanceNorm2d`) stabilise l'entra√Ænement mais peut ternir l√©g√®rement les contrastes et les couleurs ("d√©lavage"). Les mod√®les SOTA (comme EDSR) s'en passent souvent.
    * *Plan :* Entra√Æner une version identique √† la V3 mais :
        1.  Suppression de toutes les couches de Normalisation.
        2.  R√©activation des **Biais** (`bias=True`) dans les convolutions (crucial sans norm).
        3.  Diminution pr√©ventive du LR (`1e-4`) pour √©viter la divergence.
    * *But :* Comparer visuellement si la nettet√© (sharpness) est sup√©rieure au mod√®le V3.

* **B. Pipeline d'Inf√©rence & Livraison :**
    * Cr√©ation d'un script `inference.py` robuste capable de charger le mod√®le et traiter des images de Test inconnues (512x512 ou HD).
    * Int√©gration syst√©matique de la strat√©gie de **Tiling** (d√©coupage avec overlap) pour traiter n'importe quelle r√©solution sans saturation m√©moire.

* **C. Am√©lioration du Reporting :**
    * Ajout d'une **Baseline** dans les graphiques : Tracer le PSNR de l'image floue originale ("Input PSNR") pour visualiser le **Delta** r√©el apport√© par le mod√®le (ex: +5 dB) plut√¥t qu'un chiffre absolu.

C'est not√© ! Merci pour la rectification importante. C'est crucial de garder une trace des √©checs aussi, car c'est un r√©sultat scientifique en soi ("Negative Result").

Donc, pour r√©sumer la r√©alit√© historique :
1.  **Run V3 (Seed 42)** : Le Champion (31.15 val / 29.57 full).
2.  **Run V4 (Seed 123)** : La Validation Crois√©e (Architecture identique √† V3, mais nouvelle seed). Score : 27.21 dB. (Moins bon car split plus difficile).
3.  **Run "No-Norm"** : Tentative √©chou√©e, stagnation √† 26 dB, arr√™t√©e √† l'epoch 50.

Voici la mise √† jour finale et corrig√©e de ton carnet de bord. J'ai ajout√© l'exp√©rience "No-Norm" comme une tentative infructueuse (ce qui justifie le choix final de l'Instance Norm).

***

#### 11. Analyse du Run #4 (Validation Crois√©e - Robustesse)
* **Contexte Exp√©rimental :**
    * Architecture : **Identique √† V3** (InstanceNorm + Bias False + Cosine Scheduler).
    * Modification : Changement unique de la **Seed** ($42 \to 123$) pour g√©n√©rer un nouveau Split Train/Val et tester la robustesse statistique.
* **R√©sultats :**
    * **Full Resolution PSNR :** **27.21 dB**.
    * *Observation :* Chute significative par rapport au record de 29.57 dB (V3).
* **Diagnostic (Le Biais du Split) :**
    * L'analyse a r√©v√©l√© que le nouveau set de validation (Seed 123) √©tait intrins√®quement **plus difficile** que le pr√©c√©dent.
    * *Preuve :* Le mod√®le "Champion" V3 (Seed 42), r√©-√©valu√© sur ce nouveau split difficile, voit son score chuter √† **27.44 dB**.
    * *Conclusion :* Le nouveau mod√®le (27.21 dB) performe quasiment au m√™me niveau que le champion (27.44 dB) sur ce terrain difficile ($\Delta = 0.2$ dB). La robustesse de l'architecture est valid√©e.

#### 12. L'Exp√©rience "No-Norm" (Tentative Avort√©e)
* **Hypoth√®se :** Suppression de l'Instance Normalization pour gagner en fid√©lit√© de couleur (comme EDSR), avec r√©activation des biais.
* **R√©sultat :** √âchec.
* **Observation :** L'entra√Ænement a montr√© une instabilit√© et une incapacit√© √† converger vers des d√©tails fins. Le mod√®le a stagn√© √† un plateau de **~26 dB** de PSNR.
* **Action :** Run avort√©e √† l'Epoch 50.
* **Conclusion Technique :** Pour cette architecture l√©g√®re (Lightweight U-Net) et ce dataset, la normalisation (`InstanceNorm2d`) est indispensable √† la convergence.

#### 13. Conclusion Finale & Livrables
Le projet est clos avec succ√®s. L'objectif initial (mod√®le l√©ger sur Mac < 5M params avec PSNR > 28.5 dB) est d√©pass√©.

* **S√©lection du Mod√®le Final (Production) :**
    * Le mod√®le retenu est le **V3 (Seed 42)**.
    * **Specs :** 6.5M Params, 48 Filtres, InstanceNorm, Scheduler Cosine.
    * **Performance Officielle :** 31.15 dB (Val Crop) / **29.57 dB** (Full HD Moyenne).

* **Architecture Valid√©e :**
    * U-Net Lightweight optimis√© (DSConv + Upsample).
    * Pipeline d'entra√Ænement robuste (Split par S√©quence + Jitter + Tiling).

* **Outils D√©ploy√©s :**
    * **`inference.py` :** Script autonome capable de d√©flouter des images de n'importe quelle r√©solution (512px, HD, 4K) gr√¢ce √† l'int√©gration native du **Tiling** pour g√©rer la m√©moire.
    * **Visualisation :** Outils d'analyse g√©n√©rant les cartes d'erreur, les histogrammes de distribution PSNR et l'identification automatique des "Best/Worst cases" avec calcul du Delta d'am√©lioration.