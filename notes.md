### üìì Carnet de Bord : D√©veloppement U-Net Deblurring

#### 1. Probl√©matique Initiale & Contraintes
* **Architecture de base :** U-Net standard (2015).
* **Probl√®me :** Mod√®le de ~28M √† 30M de param√®tres trop lourd pour les ressources disponibles (Google Colab Free / MacBook MPS).
    * *Sympt√¥mes :* Timeout apr√®s quelques epochs, OOM (Out of Memory), it√©rations trop lentes.
* **Objectif :** Cr√©er une architecture "Lightweight" (< 5M params) capable d'apprendre efficacement sans sacrifier la capacit√© de reconstruction.

#### 2. Optimisation de l'Architecture (V1)
* **R√©duction des param√®tres :** Passage de 28M √† ~3M.
    * Remplacement des Convolutions Standards par des **Depthwise Separable Convolutions (DSConv)** (Gain : facteur ~8 sur les poids).
    * R√©duction du nombre de filtres initiaux (`start_filters`) de 64 √† 32.
    * Remplacement des `ConvTranspose2d` (lourdes, artefacts damier) par `Upsample Bilinear` + `Conv`.
* **Choix structurels :**
    * Maintien d'une convolution standard 4x4 (stride 2) pour le *Downsampling* afin de pr√©server l'information spatiale critique (responsable d'1M de params √† elle seule, mais jug√©e n√©cessaire).
    * **Global Residual Connection :** Adoption de la strat√©gie $Output = Input + Network(Input)$ pour forcer le r√©seau √† apprendre uniquement le r√©sidu (le flou) plut√¥t que de reconstruire l'image enti√®re.

#### 3. Strat√©gie de Donn√©es (Data Pipeline)
* **Training vs Inference :**
    * Entra√Ænement sur des **Random Crops (256x256)** pour g√©rer la VRAM et augmenter la diversit√© locale.
    * Validation/Test sur image compl√®te via strat√©gie de **Tiling (Tuilage)** avec *Overlap* et *Blending* pour √©viter les effets de bord sur les images HD (1280x720).
* **Data Augmentation (Crucial pour le d√©floutage) :**
    * Flip Horizontal & Vertical.
    * **Rotation 90¬∞/180¬∞/270¬∞ :** Indispensable pour varier la direction des vecteurs de flou de mouvement (transformer un flou gauche-droite en haut-bas).
    * *Note :* Application stricte de la "Joint Transform" (m√™me seed al√©atoire pour l'image floue et l'image nette).

#### 4. Adaptation Mat√©rielle (MacBook MPS)
* **Optimisation I/O :** Passage de `num_workers=4` √† `num_workers=0` pour √©viter les instabilit√©s du multiprocessing sur puce Apple Silicon.
* **Gestion M√©moire (VRAM 16Go) :**
    * D√©tection d'un OOM avec Batch Size 32 + Mod√®le 3M.
    * Ajustement du **Batch Size √† 16** (ou 32 avec *Gradient Accumulation* simul√©).
    * Utilisation de `torch.mps.empty_cache()` et `clip_grad_norm_` pour la stabilit√©.

#### 5. Analyse du Run #1 (Night Run)
* **R√©sultats :**
    * Training PSNR : **29.32 dB**
    * Validation PSNR : **27.50 dB**
* **Observations :**
    * Le mod√®le apprend bien (pas de divergence).
    * L'√©cart Train/Val (1.8 dB) sugg√®re un l√©ger "Generalization Gap", potentiellement d√ª au fait que les crops d'entra√Ænement sont parfois "faciles" (ciel uni) vs les crops de validation centr√©s (objets complexes).
    * **Probl√®me Majeur :** Le Learning Rate est rest√© constant (`2e-4`). Le scheduler `ReduceLROnPlateau` √©tait trop timide (patience trop √©lev√©e ou seuil non atteint), emp√™chant le mod√®le d'affiner les micro-d√©tails (convergence fine).

#### 6. Plan d'Action pour le Run #2 (V2)
Pour viser > 28.5 dB en validation :

1.  **Architecture (Scale Up) :** Augmentation de la largeur du mod√®le. Passage de `start_filters=32` √† **48** (environ 6.5M params) pour augmenter la capacit√© de m√©morisation des textures complexes.
2.  **Scheduler :** Remplacement de `ReduceLROnPlateau` par **`CosineAnnealingLR`**.
    * *But :* Forcer math√©matiquement la descente du LR jusqu'√† `1e-6` √† la fin de l'entra√Ænement pour garantir la phase de finition ("Fine-tuning").
3.  **R√©gularisation :**
    * Augmentation du **Weight Decay** de `1e-4` √† `1e-3` pour compenser l'augmentation de la taille du mod√®le et √©viter l'overfitting.
    * Ajout de **ColorJitter** (tr√®s l√©ger) dans l'augmentation de donn√©es pour robustifier le mod√®le face aux variations colorim√©triques.

#### 7. Intermediate Analysis (Run with Cosine Scheduler)
* **Results Achieved:**
    * **Validation PSNR:** Reached a stable plateau at **28.03 dB** (Target 28+ reached).
    * **Train PSNR:** Oscillating around **29.7 dB**.
    * **Scheduler Behavior:** The switch to `CosineAnnealingLR` is a total success. The learning curve shows a "smooth landing" and much better convergence compared to the previous plateau strategy.
* **Gap Diagnosis (Generalization Gap ~1.7 dB):**
    * The model learns well but seems to hit a ceiling in validation.
    * **Critical Discovery (Bug Fix):** Identified a logic error in `GoProDataset`. Random rotations (0, 90, 180, 270¬∞) were being applied **during validation as well** (missing indentation under `if self.is_train:`).
    * *Impact:* Validation was artificially noisy and harder than intended, likely underestimating the model's true performance.

#### 8. Optimisation Finale pour la V3 (Objectif 28.5+ dB)
Pour maximiser la performance et corriger le gap Train/Val, la strat√©gie suivante est adopt√©e :

* **A. Correction du Pipeline de Donn√©es :**
    * **Fix Rotation :** Restriction des rotations al√©atoires au mode `train` uniquement.
    * **Fix `ColorJitter` :** Correction du crash `TypeError` sur les param√®tres `hue` et impl√©mentation d'une synchronisation manuelle stricte pour garantir que l'image floue et nette subissent exactement la m√™me variation colorim√©trique.

* **B. Strat√©gie "Data Scale-Up" Rigoureuse (Split par S√©quence) :**
    * *Probl√®me Identifi√© :* Le dataset GoPro est constitu√© de s√©quences vid√©o. Un "Random Shuffle" simple des images cr√©erait une **fuite de donn√©es (Data Leakage)** massive : le mod√®le verrait la frame $t$ dans le Train et la frame $t+1$ (quasi-identique) dans la Validation, faussant le score. 
    * *Solution Scientifique :* Adoption d'un **Split par S√©quence Vid√©o**.
        * Les images sont group√©es par dossier parent (S√©quence).
        * Le m√©lange et la d√©coupe se font sur les *noms de s√©quences*, et non sur les images individuelles.
    * *Action :* R√©allocation dynamique de s√©quences du set de Test original vers le Train pour atteindre un ratio **~90% Train / 10% Val** (au lieu de 66/33).
    * *Gain Double :*
        1.  **Performance :** Le mod√®le s'entra√Æne sur ~2800 images (+33%), augmentant la diversit√© des sc√®nes apprises.
        2.  **Rigueur :** Garantie absolue qu'aucune image de validation ne provient d'une vid√©o vue √† l'entra√Ænement. La validation teste r√©ellement la g√©n√©ralisation sur une sc√®ne inconnue.

* **C. Raffinements de R√©gularisation :**
    * **Soft Color Jitter :** Ajout d'une variation al√©atoire l√©g√®re ($\pm 15\%$) de luminosit√©, contraste et saturation.
    * *But :* Forcer le mod√®le √† g√©n√©raliser sur les structures g√©om√©triques plut√¥t que de m√©moriser les histogrammes de couleurs sp√©cifiques des sc√®nes GoPro.

* **Configuration Finale Run V3 :**
    * **Architecture :** `LightweightUNet` (48 filtres initiaux).
    * **Batch Size :** 8 (avec *Gradient Accumulation* si instable).
    * **Scheduler :** `CosineAnnealingLR` (T_max=150).
    * **Dataset :** Split par S√©quence 90/10 + Augmentations corrig√©es.