{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53423561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gabriel/dev/konkuk/IA/project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1\n",
      "CUDA available: False\n",
      "âœ“ Random seeds set\n"
     ]
    }
   ],
   "source": [
    "# 1. Import Libraries\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"âœ“ Random seeds set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ece164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dataset Class (GoProDataset)\n",
    "# Copied from src/dataset.py\n",
    "\n",
    "class GoProDataset(Dataset):\n",
    "    \"\"\"\n",
    "    GoPro Image Deblurring Dataset.\n",
    "    \n",
    "    Features:\n",
    "    - On-the-fly random cropping (256x256 patches from 1280x720 images)\n",
    "    - Random horizontal flip augmentation\n",
    "    - Normalization to [0, 1] range\n",
    "    - Optional full-resolution mode (no cropping)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        blur_paths: List[str],\n",
    "        sharp_paths: List[str],\n",
    "        patch_size: int = 256,\n",
    "        is_train: bool = True,\n",
    "        full_image: bool = False\n",
    "    ):\n",
    "        assert len(blur_paths) == len(sharp_paths), \"Mismatch between blur and sharp image counts\"\n",
    "        \n",
    "        self.blur_paths = blur_paths\n",
    "        self.sharp_paths = sharp_paths\n",
    "        self.patch_size = patch_size\n",
    "        self.is_train = is_train\n",
    "        self.full_image = full_image\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.blur_paths)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Load and process a single image pair.\n",
    "        \"\"\"\n",
    "        # Load images as PIL\n",
    "        blur_img = Image.open(self.blur_paths[idx]).convert('RGB')\n",
    "        sharp_img = Image.open(self.sharp_paths[idx]).convert('RGB')\n",
    "        \n",
    "        # Apply cropping only if not using full images\n",
    "        if not self.full_image:\n",
    "            # Apply cropping (random for train, center for val/test)\n",
    "            if self.is_train:\n",
    "                # Random crop - same location for both images\n",
    "                i, j, h, w = self._get_random_crop_params(blur_img)\n",
    "            else:\n",
    "                # Center crop for validation/test\n",
    "                i, j, h, w = self._get_center_crop_params(blur_img)\n",
    "            \n",
    "            blur_img = TF.crop(blur_img, i, j, h, w)\n",
    "            sharp_img = TF.crop(sharp_img, i, j, h, w)\n",
    "        \n",
    "        # Random horizontal flip (only during training)\n",
    "        if self.is_train and random.random() > 0.5:\n",
    "            blur_img = TF.hflip(blur_img)\n",
    "            sharp_img = TF.hflip(sharp_img)\n",
    "        \n",
    "        # Convert to tensor and normalize to [0, 1]\n",
    "        blur_tensor = TF.to_tensor(blur_img)  # Converts uint8 [0, 255] to float [0, 1]\n",
    "        sharp_tensor = TF.to_tensor(sharp_img)\n",
    "        \n",
    "        return blur_tensor, sharp_tensor\n",
    "    \n",
    "    def _get_random_crop_params(self, img: Image.Image) -> Tuple[int, int, int, int]:\n",
    "        width, height = img.size\n",
    "        if width < self.patch_size or height < self.patch_size:\n",
    "            raise ValueError(f\"Image size ({width}x{height}) is smaller than patch size ({self.patch_size})\")\n",
    "        \n",
    "        top = random.randint(0, height - self.patch_size)\n",
    "        left = random.randint(0, width - self.patch_size)\n",
    "        return top, left, self.patch_size, self.patch_size\n",
    "    \n",
    "    def _get_center_crop_params(self, img: Image.Image) -> Tuple[int, int, int, int]:\n",
    "        width, height = img.size\n",
    "        top = (height - self.patch_size) // 2\n",
    "        left = (width - self.patch_size) // 2\n",
    "        return top, left, self.patch_size, self.patch_size\n",
    "\n",
    "\n",
    "def get_image_pairs(root_dir: str, split: str = 'train') -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"Recursively find blur-sharp image pairs in the dataset.\"\"\"\n",
    "    blur_paths = []\n",
    "    sharp_paths = []\n",
    "    \n",
    "    split_dir = os.path.join(root_dir, split)\n",
    "    \n",
    "    if not os.path.exists(split_dir):\n",
    "        # Fallback for Colab if path is slightly different or just to warn\n",
    "        print(f\"Warning: Directory {split_dir} does not exist. Check your data_root.\")\n",
    "        return [], []\n",
    "    \n",
    "    # Walk through sequence folders\n",
    "    for sequence_folder in sorted(os.listdir(split_dir)):\n",
    "        sequence_path = os.path.join(split_dir, sequence_folder)\n",
    "        if not os.path.isdir(sequence_path):\n",
    "            continue\n",
    "        \n",
    "        blur_dir = os.path.join(sequence_path, 'blur')\n",
    "        sharp_dir = os.path.join(sequence_path, 'sharp')\n",
    "        \n",
    "        if os.path.exists(blur_dir) and os.path.exists(sharp_dir):\n",
    "            images = sorted(os.listdir(blur_dir))\n",
    "            for img_name in images:\n",
    "                if img_name.endswith('.png'):\n",
    "                    blur_paths.append(os.path.join(blur_dir, img_name))\n",
    "                    sharp_paths.append(os.path.join(sharp_dir, img_name))\n",
    "    \n",
    "    return blur_paths, sharp_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02dfbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model Architecture (SimpleUNet)\n",
    "# Copied from src/models/unet.py\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Basic convolutional block: Conv â†’ InstanceNorm â†’ LeakyReLU.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, padding_mode='reflect', bias=False)\n",
    "        self.norm = nn.InstanceNorm2d(out_channels, affine=True)\n",
    "        self.activation = nn.LeakyReLU(0.2, inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.norm(self.conv(x)))\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"Residual Block: x + Conv(Norm(Act(Conv(Norm(Act(x))))))\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, 1, 1, padding_mode='reflect', bias=False)\n",
    "        self.norm1 = nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, 1, 1, padding_mode='reflect', bias=False)\n",
    "        self.norm2 = nn.InstanceNorm2d(channels, affine=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.act(self.norm1(self.conv1(x)))\n",
    "        out = self.norm2(self.conv2(out))\n",
    "        return out + residual\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = ConvBlock(in_channels, out_channels)\n",
    "        self.res = ResBlock(out_channels)\n",
    "        self.downsample = nn.Conv2d(out_channels, out_channels, 4, 2, 1, padding_mode='reflect', bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        features = self.res(x)\n",
    "        downsampled = self.downsample(features)\n",
    "        return features, downsampled\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, skip_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(in_channels, in_channels, 4, 2, 1, bias=False)\n",
    "        self.conv = ConvBlock(in_channels + skip_channels, out_channels)\n",
    "        self.res = ResBlock(out_channels)\n",
    "    \n",
    "    def forward(self, x, skip):\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv(x)\n",
    "        x = self.res(x)\n",
    "        return x\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple U-Net for image deblurring with Global Residual Learning.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, out_channels=3, global_residual=True):\n",
    "        super().__init__()\n",
    "        self.global_residual = global_residual\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder1 = EncoderBlock(in_channels, 64)\n",
    "        self.encoder2 = EncoderBlock(64, 128)\n",
    "        self.encoder3 = EncoderBlock(128, 256)\n",
    "        self.encoder4 = EncoderBlock(256, 512)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder4 = DecoderBlock(512, 512, 256)\n",
    "        self.decoder3 = DecoderBlock(256, 256, 128)\n",
    "        self.decoder2 = DecoderBlock(128, 128, 64)\n",
    "        self.decoder1 = DecoderBlock(64, 64, 64)\n",
    "        \n",
    "        # Output\n",
    "        self.output = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "        # Zero Initialization for Residual Learning\n",
    "        if global_residual:\n",
    "            nn.init.constant_(self.output.weight, 0)\n",
    "            if self.output.bias is not None:\n",
    "                nn.init.constant_(self.output.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_image = x if self.global_residual else None\n",
    "        \n",
    "        skip1, x = self.encoder1(x)\n",
    "        skip2, x = self.encoder2(x)\n",
    "        skip3, x = self.encoder3(x)\n",
    "        skip4, x = self.encoder4(x)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        x = self.decoder4(x, skip4)\n",
    "        x = self.decoder3(x, skip3)\n",
    "        x = self.decoder2(x, skip2)\n",
    "        x = self.decoder1(x, skip1)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        \n",
    "        if self.global_residual:\n",
    "            x = x + input_image\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1824b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Metrics\n",
    "# Copied from src/utils/metrics.py\n",
    "\n",
    "class PSNRMetric:\n",
    "    \"\"\"Accumulates PSNR values across batches.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.total_psnr = 0.0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, pred, target):\n",
    "        # Calculate PSNR for current batch\n",
    "        with torch.no_grad():\n",
    "            # Clamp to [0, 1]\n",
    "            pred = torch.clamp(pred, 0, 1)\n",
    "            target = torch.clamp(target, 0, 1)\n",
    "            \n",
    "            mse = F.mse_loss(pred, target, reduction='none').mean(dim=[1, 2, 3])\n",
    "            # Handle perfect matches\n",
    "            mse[mse == 0] = 1e-10\n",
    "            \n",
    "            psnr = 10 * torch.log10(1.0 / mse)\n",
    "            self.total_psnr += psnr.sum().item()\n",
    "            self.count += pred.size(0)\n",
    "            \n",
    "    def compute(self):\n",
    "        return self.total_psnr / self.count if self.count > 0 else 0.0\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    \"\"\"Helper for single batch PSNR calculation.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        mse = F.mse_loss(img1, img2)\n",
    "        if mse == 0: return 100.0\n",
    "        return 10 * torch.log10(1.0 / mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "298ebe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Data Root: ./data\n",
      "  Batch Size: 8\n",
      "  Learning Rate: 0.0002\n",
      "  Sanity Check: False\n"
     ]
    }
   ],
   "source": [
    "# 5. Configuration\n",
    "class Config:\n",
    "    \"\"\"Training configuration\"\"\"\n",
    "    \n",
    "    # Data\n",
    "    data_root = './data'    # CHANGE THIS PATH ON COLAB (e.g., '/content/drive/MyDrive/GoPro')\n",
    "    patch_size = 256        # Crop size for training\n",
    "    batch_size = 8          # Batch size\n",
    "    num_workers = 2         # Lower workers for Colab safety\n",
    "    \n",
    "    # Model\n",
    "    in_channels = 3\n",
    "    out_channels = 3\n",
    "    \n",
    "    # Training\n",
    "    num_epochs = 100        \n",
    "    learning_rate = 2e-4    # Stable LR for residual learning\n",
    "    weight_decay = 1e-4     \n",
    "    \n",
    "    # Loss function\n",
    "    loss_type = 'charbonnier'\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler_patience = 10\n",
    "    scheduler_factor = 0.5\n",
    "    \n",
    "    # Checkpointing\n",
    "    save_dir = './experiments'\n",
    "    experiment_name = 'simple_unet_colab'\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stop_patience = 20\n",
    "    \n",
    "    # Sanity check mode\n",
    "    sanity_check = False    # Set to True to overfit on 10 images first\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Create save directory\n",
    "os.makedirs(config.save_dir, exist_ok=True)\n",
    "experiment_dir = os.path.join(config.save_dir, config.experiment_name)\n",
    "os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Data Root: {config.data_root}\")\n",
    "print(f\"  Batch Size: {config.batch_size}\")\n",
    "print(f\"  Learning Rate: {config.learning_rate}\")\n",
    "print(f\"  Sanity Check: {config.sanity_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b46f29cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU (training will be slow!)\n"
     ]
    }
   ],
   "source": [
    "# 6. Device Setup\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU (training will be slow!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90e81e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: CHARBONNIER\n"
     ]
    }
   ],
   "source": [
    "# 7. Loss Function\n",
    "class CharbonnierLoss(nn.Module):\n",
    "    \"\"\"Smooth L1 Loss: sqrt(diff^2 + epsilon^2)\"\"\"\n",
    "    def __init__(self, epsilon=1e-3):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        diff = pred - target\n",
    "        loss = torch.sqrt(diff * diff + self.epsilon * self.epsilon)\n",
    "        return loss.mean()\n",
    "\n",
    "def get_loss_function(loss_type='l1'):\n",
    "    if loss_type == 'l1': return nn.L1Loss()\n",
    "    elif loss_type == 'mse': return nn.MSELoss()\n",
    "    elif loss_type == 'charbonnier': return CharbonnierLoss()\n",
    "    else: raise ValueError(f\"Unknown loss type: {loss_type}\")\n",
    "\n",
    "criterion = get_loss_function(config.loss_type)\n",
    "print(f\"Loss function: {config.loss_type.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4cd71e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Found 2103 training pairs\n",
      "Found 1111 test pairs\n",
      "âœ“ Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# 8. Load Data\n",
    "print(\"Loading data...\")\n",
    "train_blur, train_sharp = get_image_pairs(config.data_root, 'train')\n",
    "test_blur, test_sharp = get_image_pairs(config.data_root, 'test')\n",
    "\n",
    "print(f\"Found {len(train_blur)} training pairs\")\n",
    "print(f\"Found {len(test_blur)} test pairs\")\n",
    "\n",
    "if len(train_blur) == 0:\n",
    "    print(\"âš ï¸ NO DATA FOUND! Please check Config.data_root path.\")\n",
    "else:\n",
    "    # Sanity check mode logic\n",
    "    if config.sanity_check:\n",
    "        train_blur = train_blur[:10]\n",
    "        train_sharp = train_sharp[:10]\n",
    "        test_blur = train_blur \n",
    "        test_sharp = train_sharp\n",
    "        print(f\"ðŸ”¬ SANITY CHECK MODE: Using {len(train_blur)} samples\")\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = GoProDataset(\n",
    "        train_blur, train_sharp, \n",
    "        patch_size=config.patch_size, \n",
    "        is_train=not config.sanity_check\n",
    "    )\n",
    "\n",
    "    val_dataset = GoProDataset(\n",
    "        test_blur, test_sharp, \n",
    "        patch_size=config.patch_size, \n",
    "        is_train=False\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=not config.sanity_check,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    print(\"âœ“ Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "620df01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 28,480,003\n",
      "âœ“ Model initialized\n"
     ]
    }
   ],
   "source": [
    "# 9. Initialize Model & Optimizer\n",
    "model = SimpleUNet(\n",
    "    in_channels=config.in_channels,\n",
    "    out_channels=config.out_channels,\n",
    "    global_residual=True\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',\n",
    "    factor=config.scheduler_factor,\n",
    "    patience=config.scheduler_patience,\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(\"âœ“ Model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cec5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Training Functions\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    psnr_metric = PSNRMetric()\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "    \n",
    "    for blur, sharp in pbar:\n",
    "        blur, sharp = blur.to(device), sharp.to(device)\n",
    "        \n",
    "        output = model(blur)\n",
    "        loss = criterion(output, sharp)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        psnr_metric.update(output.detach(), sharp)\n",
    "        \n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'psnr': f\"{psnr_metric.compute():.2f}\"})\n",
    "    \n",
    "    return running_loss / len(train_loader), psnr_metric.compute()\n",
    "\n",
    "def validate(model, val_loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    psnr_metric = PSNRMetric()\n",
    "    \n",
    "    pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]  \")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for blur, sharp in pbar:\n",
    "            blur, sharp = blur.to(device), sharp.to(device)\n",
    "            output = model(blur)\n",
    "            loss = criterion(output, sharp)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            psnr_metric.update(output, sharp)\n",
    "            \n",
    "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'psnr': f\"{psnr_metric.compute():.2f}\"})\n",
    "    \n",
    "    return running_loss / len(val_loader), psnr_metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f7aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Main Training Loop\n",
    "history = {'train_loss': [], 'train_psnr': [], 'val_loss': [], 'val_psnr': [], 'lr': []}\n",
    "best_psnr = 0.0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(config.num_epochs):\n",
    "    # Train\n",
    "    train_loss, train_psnr = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_psnr = validate(model, val_loader, criterion, device, epoch)\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler.step(val_psnr)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # History\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_psnr'].append(train_psnr)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_psnr'].append(val_psnr)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train PSNR={train_psnr:.2f}dB | Val PSNR={val_psnr:.2f}dB | LR={current_lr:.2e}\")\n",
    "    \n",
    "    # Save Best\n",
    "    if val_psnr > best_psnr:\n",
    "        best_psnr = val_psnr\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'best_psnr': best_psnr,\n",
    "        }, os.path.join(experiment_dir, 'best_model.pth'))\n",
    "        print(f\"  âœ“ Saved best model ({best_psnr:.2f} dB)\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "    \n",
    "    if epochs_without_improvement >= config.early_stop_patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "print(f\"Training complete. Best PSNR: {best_psnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b148b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Visualization\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train')\n",
    "plt.plot(history['val_loss'], label='Val')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_psnr'], label='Train')\n",
    "plt.plot(history['val_psnr'], label='Val')\n",
    "plt.title('PSNR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Sample Predictions\n",
    "# Load best model\n",
    "checkpoint = torch.load(os.path.join(experiment_dir, 'best_model.pth'), map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Visualize\n",
    "n_samples = 3\n",
    "indices = random.sample(range(len(val_dataset)), min(n_samples, len(val_dataset)))\n",
    "\n",
    "fig, axes = plt.subplots(n_samples, 3, figsize=(15, 5*n_samples))\n",
    "if n_samples == 1: axes = axes.reshape(1, -1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(indices):\n",
    "        blur, sharp = val_dataset[idx]\n",
    "        blur_in = blur.unsqueeze(0).to(device)\n",
    "        pred = model(blur_in).cpu().squeeze(0)\n",
    "        \n",
    "        psnr = calculate_psnr(pred.unsqueeze(0), sharp.unsqueeze(0)).item()\n",
    "        \n",
    "        axes[i, 0].imshow(blur.permute(1, 2, 0).numpy())\n",
    "        axes[i, 0].set_title(\"Blur\")\n",
    "        axes[i, 1].imshow(torch.clamp(pred, 0, 1).permute(1, 2, 0).numpy())\n",
    "        axes[i, 1].set_title(f\"Pred (PSNR: {psnr:.2f} dB)\")\n",
    "        axes[i, 2].imshow(sharp.permute(1, 2, 0).numpy())\n",
    "        axes[i, 2].set_title(\"Sharp\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
